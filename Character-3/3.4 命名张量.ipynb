{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ac43b7e-f161-484f-b010-df5038c57997",
   "metadata": {},
   "source": [
    "# 3.4 命名张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72f23ce5-cbfc-4bcc-96f9-2bafa819e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10e7cbb8-7999-4480-b359-714d956cb536",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t = torch.randn(3, 5, 5)  # [channels, rows, columns]\n",
    "weights = torch.tensor([0.2126, 0.7152, 0.0722])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66e70a4a-5bf0-42e3-b0b6-b4e4a27e80f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.8049, -0.9717, -0.0176,  0.0480, -1.6187],\n",
       "          [ 1.4615, -0.3896, -0.7374,  0.1102, -0.9746],\n",
       "          [-0.3539, -0.8203, -1.7512, -0.8435,  0.1149],\n",
       "          [-0.3396, -1.0138,  0.3745, -0.8341,  0.7421],\n",
       "          [ 0.5616,  1.3539, -0.4092,  1.6163, -0.5062]],\n",
       "\n",
       "         [[ 2.1046, -1.1459,  0.6569,  1.1386, -0.2118],\n",
       "          [ 1.0382, -0.1674, -0.3051,  1.1797, -0.7329],\n",
       "          [-1.0447,  1.2614,  0.4393,  0.2438,  1.3825],\n",
       "          [-1.6290,  1.4842, -0.0318, -0.4689, -0.1393],\n",
       "          [ 1.5381,  0.6903, -0.4920,  1.7336, -0.6744]],\n",
       "\n",
       "         [[-0.7449,  0.3898, -0.9506,  0.1552, -0.6337],\n",
       "          [ 0.8725,  0.9979,  1.4142, -0.2129, -1.8962],\n",
       "          [-0.2822,  0.9340, -1.5762, -0.3484,  0.3663],\n",
       "          [ 1.3197, -0.1514, -0.5578,  0.2283,  2.0495],\n",
       "          [ 1.4063, -0.1903,  0.5246, -2.2835, -0.8044]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4142, -1.5966, -1.2653,  1.9121,  1.7859],\n",
       "          [-0.6382, -0.5264, -0.6884,  2.1047, -1.1718],\n",
       "          [-0.3149,  1.0741,  1.3466,  1.1330, -0.3179],\n",
       "          [-0.3733,  0.3511, -0.2659, -0.6397, -1.3194],\n",
       "          [-0.1163, -0.1848, -0.8973,  1.9315,  0.5484]],\n",
       "\n",
       "         [[ 0.5133,  0.7782,  0.8081,  0.6116, -0.2862],\n",
       "          [-0.1490, -0.9025,  0.1707, -1.2730, -0.4773],\n",
       "          [ 0.4299, -0.8755, -1.6043,  0.8862, -0.5168],\n",
       "          [ 1.1714,  1.9813, -2.3366,  0.1794,  2.1020],\n",
       "          [-0.6670, -0.9374,  0.6397, -0.7739, -0.3327]],\n",
       "\n",
       "         [[-2.0384,  0.2939, -0.0707,  0.6266,  0.7140],\n",
       "          [ 3.0028,  1.3088, -0.7492, -1.4054,  1.9482],\n",
       "          [-0.5441, -0.6569,  0.9005,  2.2135,  0.3277],\n",
       "          [ 0.6485,  0.0918,  0.8827, -1.4400, -0.1918],\n",
       "          [ 0.1810,  1.8119, -2.6122,  0.3308,  0.7998]]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_t = torch.randn(2, 3, 5, 5)  # [batch, channels, rows, columns]\n",
    "batch_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b18376b8-f423-466c-a2a8-445688b632a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1484, -0.5759, -0.1038,  0.4473, -0.8214],\n",
       "         [ 1.1241,  0.1470,  0.1239,  0.3590, -1.2012],\n",
       "         [-0.5603,  0.4584, -0.9627, -0.3160,  0.6212],\n",
       "         [-0.2163,  0.1064, -0.0717, -0.3582,  0.8841],\n",
       "         [ 1.1686,  0.6180, -0.1255,  0.3555, -0.6617]],\n",
       "\n",
       "        [[-0.3703, -0.1748, -0.1760,  1.0501,  0.7379],\n",
       "         [ 0.7385, -0.0401, -0.4223, -0.1912,  0.0997],\n",
       "         [-0.1430, -0.1528,  0.2143,  1.4109, -0.1690],\n",
       "         [ 0.4822,  0.8081, -0.5733, -0.6334,  0.1969],\n",
       "         [-0.2008,  0.2299, -0.9566,  0.4961,  0.3385]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 无论是img_t还是batch_t，通道总是在到数第三维\n",
    "img_gray_naive = img_t.mean(-3)  # 未加权平均值\n",
    "batch_gray_naive = batch_t.mean(-3)\n",
    "img_gray_naive.shape, batch_gray_naive.shape\n",
    "batch_gray_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa82a73f-01c1-4247-8017-93b5c8f41b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.2126]],\n",
       " \n",
       "         [[0.7152]],\n",
       " \n",
       "         [[0.0722]]]),\n",
       " torch.Size([3, 1, 1]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze_(-1)\n",
    "unsqueezed_weights, unsqueezed_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d98a212-7c1b-485b-805d-5150224d4aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_weights = (img_t * unsqueezed_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7d77b2f-cae8-4dcf-ab16-7ab2080c94de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 5, 5]), torch.Size([2, 3, 5, 5]), torch.Size([3, 1, 1]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_weights = (batch_t * unsqueezed_weights)\n",
    "img_gray_weighted = img_weights.sum(-3)\n",
    "batch_gray_weighted = batch_weights.sum(-3)\n",
    "batch_weights.shape, batch_t.shape, unsqueezed_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8abf9401-ba6b-4a8e-86cc-604f7a9bf1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722], names=('channels',))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])  # 不完善，不推荐使用\n",
    "weight_named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4e33999-3a18-451a-89bc-f7a47f72b140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_named =  tensor([[[ 0.0385, -0.3649,  2.7373, -0.3059, -0.0469],\n",
      "         [ 0.2849,  0.7005, -0.6866,  1.0402,  0.2086],\n",
      "         [-2.2385,  0.7690,  0.5817, -0.3867, -0.1264],\n",
      "         [-0.9652,  0.1821,  0.6466, -1.0478, -1.4644],\n",
      "         [ 0.2333, -0.3140, -0.2550,  0.3320,  0.1800]],\n",
      "\n",
      "        [[-1.1196,  0.9159,  0.6445,  0.9326, -0.3281],\n",
      "         [-1.8946,  1.0960,  0.3911,  0.9495, -0.0360],\n",
      "         [-0.9403,  1.6035, -0.4780,  1.1621, -2.4318],\n",
      "         [ 0.3130,  0.5495,  0.4919,  0.2342,  1.1146],\n",
      "         [ 0.8867, -0.2159, -0.8617, -0.3839,  1.0642]],\n",
      "\n",
      "        [[-0.2113, -0.6133, -1.0702,  0.2439,  1.2256],\n",
      "         [-0.1301,  0.2028,  0.5876, -1.0001, -0.3201],\n",
      "         [ 0.3081,  0.6901,  0.0130, -1.2328,  0.0689],\n",
      "         [-2.7124,  0.3469,  0.3159,  0.1472, -1.1801],\n",
      "         [ 1.1296, -0.2698,  0.8229,  0.6928, -1.1419]]],\n",
      "       names=('channels', 'rows', 'columns'))\n",
      "batch_named =  tensor([[[[-1.8049, -0.9717, -0.0176,  0.0480, -1.6187],\n",
      "          [ 1.4615, -0.3896, -0.7374,  0.1102, -0.9746],\n",
      "          [-0.3539, -0.8203, -1.7512, -0.8435,  0.1149],\n",
      "          [-0.3396, -1.0138,  0.3745, -0.8341,  0.7421],\n",
      "          [ 0.5616,  1.3539, -0.4092,  1.6163, -0.5062]],\n",
      "\n",
      "         [[ 2.1046, -1.1459,  0.6569,  1.1386, -0.2118],\n",
      "          [ 1.0382, -0.1674, -0.3051,  1.1797, -0.7329],\n",
      "          [-1.0447,  1.2614,  0.4393,  0.2438,  1.3825],\n",
      "          [-1.6290,  1.4842, -0.0318, -0.4689, -0.1393],\n",
      "          [ 1.5381,  0.6903, -0.4920,  1.7336, -0.6744]],\n",
      "\n",
      "         [[-0.7449,  0.3898, -0.9506,  0.1552, -0.6337],\n",
      "          [ 0.8725,  0.9979,  1.4142, -0.2129, -1.8962],\n",
      "          [-0.2822,  0.9340, -1.5762, -0.3484,  0.3663],\n",
      "          [ 1.3197, -0.1514, -0.5578,  0.2283,  2.0495],\n",
      "          [ 1.4063, -0.1903,  0.5246, -2.2835, -0.8044]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4142, -1.5966, -1.2653,  1.9121,  1.7859],\n",
      "          [-0.6382, -0.5264, -0.6884,  2.1047, -1.1718],\n",
      "          [-0.3149,  1.0741,  1.3466,  1.1330, -0.3179],\n",
      "          [-0.3733,  0.3511, -0.2659, -0.6397, -1.3194],\n",
      "          [-0.1163, -0.1848, -0.8973,  1.9315,  0.5484]],\n",
      "\n",
      "         [[ 0.5133,  0.7782,  0.8081,  0.6116, -0.2862],\n",
      "          [-0.1490, -0.9025,  0.1707, -1.2730, -0.4773],\n",
      "          [ 0.4299, -0.8755, -1.6043,  0.8862, -0.5168],\n",
      "          [ 1.1714,  1.9813, -2.3366,  0.1794,  2.1020],\n",
      "          [-0.6670, -0.9374,  0.6397, -0.7739, -0.3327]],\n",
      "\n",
      "         [[-2.0384,  0.2939, -0.0707,  0.6266,  0.7140],\n",
      "          [ 3.0028,  1.3088, -0.7492, -1.4054,  1.9482],\n",
      "          [-0.5441, -0.6569,  0.9005,  2.2135,  0.3277],\n",
      "          [ 0.6485,  0.0918,  0.8827, -1.4400, -0.1918],\n",
      "          [ 0.1810,  1.8119, -2.6122,  0.3308,  0.7998]]]],\n",
      "       names=(None, 'channels', 'rows', 'columns'))\n"
     ]
    }
   ],
   "source": [
    "img_named = img_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "batch_named = batch_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "print(\"img_named = \", img_named)\n",
    "print(\"batch_named = \", batch_named)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08df8f8-96ad-4eb2-9e89-23d8680f00cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
